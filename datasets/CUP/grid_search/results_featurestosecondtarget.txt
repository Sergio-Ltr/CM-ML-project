CUP:
1: {'loss': 0.7668283953845247, 'layers': 3, 'units': 32, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': 'None', 'regularization_lambda': 0, 'dropout': 0, 'epochs': 71}2: {'loss': 0.7755135968952308, 'layers': 1, 'units': 26, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': 'None', 'regularization_lambda': 0, 'dropout': 0, 'epochs': 163}3: {'loss': 0.778300832300012, 'layers': 1, 'units': 28, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': 'None', 'regularization_lambda': 0, 'dropout': 0, 'epochs': 118}4: {'loss': 0.7824012213794196, 'layers': 1, 'units': 23, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': 'None', 'regularization_lambda': 0, 'dropout': 0, 'epochs': 133}5: {'loss': 0.7872079237589568, 'layers': 1, 'units': 34, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': 'None', 'regularization_lambda': 0, 'dropout': 0, 'epochs': 97}6: {'loss': 0.7883219670289572, 'layers': 1, 'units': 20, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': 'None', 'regularization_lambda': 0, 'dropout': 0, 'epochs': 172}7: {'loss': 0.788482187403187, 'layers': 1, 'units': 31, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': 'None', 'regularization_lambda': 0, 'dropout': 0, 'epochs': 94}8: {'loss': 0.7942141225364209, 'layers': 1, 'units': 24, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': 'None', 'regularization_lambda': 0, 'dropout': 0, 'epochs': 148}9: {'loss': 0.8104872447087139, 'layers': 1, 'units': 27, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': 'None', 'regularization_lambda': 0, 'dropout': 0, 'epochs': 128}10: {'loss': 0.8140561507016577, 'layers': 2, 'units': 26, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': 'None', 'regularization_lambda': 0, 'dropout': 0, 'epochs': 94}