CUP:
1: {'loss': 1.1240052786729418, 'layers': 0, 'units': 22, 'learning_rate': 0.0025, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': 'L2', 'regularization_lambda': 1e-06, 'dropout': 0, 'epochs': 910.3333333333334}2: {'loss': 1.1244767365551844, 'layers': 0, 'units': 25, 'learning_rate': 0.000625, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': 'L2', 'regularization_lambda': 1e-06, 'dropout': 0, 'epochs': 1632.6666666666667}3: {'loss': 1.128618047452461, 'layers': 0, 'units': 22, 'learning_rate': 0.000625, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0.5, 'regularizator': 'L2', 'regularization_lambda': 1e-06, 'dropout': 0, 'epochs': 1489.0}4: {'loss': 1.130483672560491, 'layers': 0, 'units': 25, 'learning_rate': 0.000625, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0.5, 'regularizator': 'L2', 'regularization_lambda': 1e-06, 'dropout': 0, 'epochs': 747.0}5: {'loss': 1.1310273124944246, 'layers': 0, 'units': 25, 'learning_rate': 0.0025, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': 'L2', 'regularization_lambda': 1e-06, 'dropout': 0, 'epochs': 817.0}6: {'loss': 1.1311848249957064, 'layers': 0, 'units': 25, 'learning_rate': 0.000625, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': 'L2', 'regularization_lambda': 1e-06, 'dropout': 0, 'epochs': 1339.0}7: {'loss': 1.1319397536261022, 'layers': 0, 'units': 23, 'learning_rate': 0.000625, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': 'L2', 'regularization_lambda': 1e-06, 'dropout': 0, 'epochs': 1745.0}8: {'loss': 1.1320949997918393, 'layers': 0, 'units': 24, 'learning_rate': 0.000625, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0.8, 'regularizator': 'L2', 'regularization_lambda': 1e-06, 'dropout': 0, 'epochs': 888.0}9: {'loss': 1.1323814187088663, 'layers': 0, 'units': 24, 'learning_rate': 0.000625, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': 'L2', 'regularization_lambda': 1e-06, 'dropout': 0, 'epochs': 1527.6666666666667}10: {'loss': 1.1333224437188256, 'layers': 0, 'units': 24, 'learning_rate': 0.0025, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': 'L2', 'regularization_lambda': 1e-06, 'dropout': 0, 'epochs': 531.0}