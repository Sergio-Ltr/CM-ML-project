CUP:
1: {'loss': 0.7163582498322376, 'layers': 3, 'units': 30, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': None, 'regularization_lambda': 0.005, 'epochs': 522}2: {'loss': 0.7211967106852893, 'layers': 3, 'units': 29, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': None, 'regularization_lambda': 0.15, 'epochs': 526}3: {'loss': 0.7295272639478647, 'layers': 3, 'units': 29, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': None, 'regularization_lambda': 0.005, 'epochs': 584}4: {'loss': 0.7560195818325386, 'layers': 3, 'units': 29, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': <function L2 at 0x7fc393dbe160>, 'regularization_lambda': 0.15, 'epochs': 410}5: {'loss': 0.7595501227738539, 'layers': 3, 'units': 31, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': None, 'regularization_lambda': 0.15, 'epochs': 423}6: {'loss': 0.7625534906360327, 'layers': 3, 'units': 30, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': <function L2 at 0x7fc393dbe160>, 'regularization_lambda': 0.005, 'epochs': 363}7: {'loss': 0.7845202395972484, 'layers': 3, 'units': 28, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': <function L2 at 0x7fc393dbe160>, 'regularization_lambda': 0.005, 'epochs': 373}8: {'loss': 0.7941497530688366, 'layers': 3, 'units': 31, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': <function L2 at 0x7fc393dbe160>, 'regularization_lambda': 0.005, 'epochs': 349}9: {'loss': 0.8005472371188369, 'layers': 3, 'units': 30, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': None, 'regularization_lambda': 0.15, 'epochs': 358}10: {'loss': 0.8062682523475367, 'layers': 3, 'units': 28, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': None, 'regularization_lambda': 0.005, 'epochs': 324}