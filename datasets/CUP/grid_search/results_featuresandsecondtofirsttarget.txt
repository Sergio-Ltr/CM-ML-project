CUP:
1: {'loss': 0.330317693308222, 'layers': 1, 'units': 32, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0.5, 'regularizator': 'None', 'regularization_lambda': 0, 'dropout': 0, 'epochs': 127}2: {'loss': 0.3411194331370274, 'layers': 1, 'units': 28, 'learning_rate': 0.0001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0.8, 'regularizator': 'None', 'regularization_lambda': 0, 'dropout': 0, 'epochs': 184}3: {'loss': 0.34376532071935534, 'layers': 1, 'units': 32, 'learning_rate': 0.0001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0.8, 'regularizator': 'None', 'regularization_lambda': 0, 'dropout': 0, 'epochs': 122}4: {'loss': 0.3471768979515812, 'layers': 1, 'units': 28, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0.5, 'regularizator': 'None', 'regularization_lambda': 0, 'dropout': 0, 'epochs': 64}5: {'loss': 0.3591069099279923, 'layers': 1, 'units': 32, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': 'None', 'regularization_lambda': 0, 'dropout': 0, 'epochs': 82}6: {'loss': 0.3594503465795063, 'layers': 1, 'units': 28, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': 'None', 'regularization_lambda': 0, 'dropout': 0, 'epochs': 119}7: {'loss': 0.3606237794615304, 'layers': 1, 'units': 28, 'learning_rate': 0.0001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0.5, 'regularizator': 'None', 'regularization_lambda': 0, 'dropout': 0, 'epochs': 343}8: {'loss': 0.3638491153286427, 'layers': 1, 'units': 32, 'learning_rate': 0.0001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0, 'regularizator': 'None', 'regularization_lambda': 0, 'dropout': 0, 'epochs': 397}9: {'loss': 0.3659932253619734, 'layers': 1, 'units': 28, 'learning_rate': 0.001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0.8, 'regularizator': 'None', 'regularization_lambda': 0, 'dropout': 0, 'epochs': 56}10: {'loss': 0.38366634774825187, 'layers': 1, 'units': 32, 'learning_rate': 0.0001, 'batch_size': 1, 'init_function': 'normalized_xavier', 'momentum': 0.5, 'regularizator': 'None', 'regularization_lambda': 0, 'dropout': 0, 'epochs': 270}